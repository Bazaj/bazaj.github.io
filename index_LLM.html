<!DOCTYPE html>
<html>
	<head>
			<!-- BAZAJ FRANCESCO 	2^F 	20/04/2023 -->
		<title>LE IA</title>
			<!-- qui ho inserito una "favicon", cioè l'immagine (in questo caso Beethoven) che compare vicino 
			al titolo della pagina-->
		<link rel="icon" type="image/x-icon" href="favicon-32x32.png">
			<!-- il tag <meta> specifica i metadata in un documento HTML (matadata sono infomazioni sui dati) -->
			<!-- l'attributo "charset" specifica il set di caratteri da utilizzare, in questo caso "UTF-8", che include 
			quasi tutti i caratteri e i simboli al mondo -->
		<meta charset="UTF-8">
			<!-- l'attributo "name" con il valore "viewport" permette di adattare la pagina alla grandezza di qualsiasi schermo -->
		<meta name="viewport" content="width=device-width, initial-scale=1">
			<!-- il tag <link> instaura una relazione tra il documento attuale ed una risorsa esterna, 
			in questi casi w3CSS (il CSS di w3schools per container ecc...), la font family "raleway" di google e "font awesome" -->
		<link rel="stylesheet" href="https://www.w3schools.com/w3css/4/w3.css">
		<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Raleway">
		<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
			<!-- il tag <style> in head corrisponde ad un CSS interno, cioè applica modifiche a tutti i tag specificati, 
			ed in questo caso è presente anche una classe (.bgimg) -->
		<style>
			body,h1 {
			font-family: "Raleway", sans-serif;
			}

			p,h3,h4,h6 {
				color: white;
			}

			body, html {
				height: 100%;
				background-color: black;
			}
			
			.bgimg {
				background-image: url('https://openaicom.imgix.net/44fefabe-41f8-4dbf-9218-b1e1c44dc319/introducing-chatgpt-and-whisper-apis.jpg?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=%2C%2C%2C&w=2000');
				height: 100%;
				width: 100;
				background-attachment: fixed;
				background-position: center;
				background-size: cover;
				background-repeat: no-repeat;
			}
		</style>
	</head>
	<body>
		<!-- Navbar -->
		<div class="w3-top">
			<div class="w3-bar">
				<a href="index.html" class="w3-bar-item w3-black w3-button transition">Introduzione</a>
				<a href="index_LLM.html" class="w3-bar-item w3-black w3-button transition"><i class="fa fa-align-center"></i>LLM</a>
				<a href="index_TTI.html" class="w3-bar-item w3-black w3-button transition"><i class="fa fa-object-group"></i>TTI</a>
			</div>
		</div>
		
	<!-- Inizio pagina -->
		<!-- Background con parallax -->
		<!--"background-attachment: fixed" nel CSS è ciò che permette l'effetto parallax dell'immagine, in quanto blocca
		sul posto l'immagine rispetto al resto della pagina-->
		<div class="bgimg w3-display-container w3-animate-opacity w3-text-white">
			<!-- Animazione testo inizio pagina -->
			<div class="w3-display-middle">
				<h1 class="w3-xxlarge w3-center w3-animate-top w3-animate-opacity w3-padding-large"><span class="w3-hide-small">Gli</span> LLM</h1>
				<hr class="w3-border-grey" style="margin:auto;width:40%">
				<p class="w3-large w3-center w3-animate-top w3-animate-opacity w3-white w3-padding-large">Large Language Model</p>
			</div>
		</div>
	<!-- Contenuti -->
		<!-- Container generale -->
		<div class="w3-content w3-container w3-padding-64">
			<!-- LLM -->
			<h3 class="w3-center">COS'È UN LLM</h3>
			<div class="w3-row">
				<div class="w3-col m6 w3-center w3-padding-large">
					<img src="https://openaicom.imgix.net/fc9f7fff-2914-4204-98e9-da61462fecdd/introducing-text-and-code-embeddings.jpg?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2048%2C2048&w=2000" class="w3-round w3-image" width="500" height="333" style="margin-top:25%; margin-right:5%;">
				</div>
				<div class="w3-col m6 w3-padding-large">
					<p>Un Large Language Model (LLM) è un tipo di modello di intelligenza artificiale (AI) progettato per comprendere e generare il linguaggio naturale umano. In particolare, un LLM utilizza tecniche di apprendimento automatico (Machine Learning) e di elaborazione del linguaggio naturale (Natural Language Processing, NLP) per analizzare grandi quantità di testo e identificare schemi e modelli.
						<br>
						Un LLM può essere addestrato su molteplici fonti di testo, come ad esempio articoli di giornale, libri, conversazioni, e-mail e persino post sui social media. In questo modo, può apprendere il modo in cui gli esseri umani usano il linguaggio e generare autonomamente testo in modo simile a come farebbe una persona. Questo lo rende utile per una vasta gamma di applicazioni, come ad esempio la generazione di testo automatizzata, la traduzione automatica, l'elaborazione del linguaggio naturale e l'assistenza virtuale.
						<br><br>
						Uno degli esempi più noti di LLM è GPT-3 (Generative Pre-trained Transformer 3) ed il suo recente succssore, GPT-4, sviluppato da OpenAI, che ha suscitato un notevole interesse grazie alla sua capacità di generare testo coerente e convincente in una vasta gamma di contesti. Tuttavia, i LLM possono essere utilizzati anche per scopi meno noti, come ad esempio la creazione di chatbot o di assistenti virtuali per le aziende, o per la ricerca e l'analisi di grandi quantità di testo in vari campi.	
					</p>
				</div>
			</div>
			<hr class="w3-border-grey" style="margin:auto; width:40%; margin-top:5%; margin-bottom:5%">

			<!-- LLM più noti -->
			<h3 class="w3-center">LLM PIÙ NOTI</h3>
			<h6 class="w3-center"><em>cliccare sulle immagini per reinderizzarsi alle rispettive pagine</em></h6>
			<div class="w3-row">
				<div class="w3-col m6 w3-center w3-padding-large">
					<a href="https://openai.com/product/gpt-4"><img src="https://openaicom.imgix.net/d0a85fe2-47d9-4903-9304-11953c9e6462/gpt-3-edit-insert.jpg?auto=compress%2Cformat&fit=min&fm=jpg&q=80&rect=0%2C0%2C2048%2C2048&w=2000" class="w3-round w3-image w3-hover-opacity" width="500" height="333" style="margin-top: 30%"></a>
				</div>
				<h4 style="margin-top:5%;" class="w3-center">GPT-4</h4>
				<div class="w3-col m6 w3-padding-large">
					<p>Sviluppato da OpenAI, attualmente GPT-4 è uno degli LLM più avanzati. GPT-4 può risolvere problemi difficili con una maggiore precisione, grazie alla sua più ampia conoscenza generale e alle sue capacità di risoluzione dei problemi.
						<br><br>
						GPT-4 è creativo collaborativo. Può generare, modificare e iterare con gli utenti su attività di scrittura creativa e tecnica, come comporre canzoni, scrivere sceneggiature o apprendere lo stile di scrittura di un utente.
						<br><br>
						GPT-4 può accettare immagini come input e generare didascalie, classificazioni e analisi.
						<br><br>
						GPT-4 è in grado di gestire oltre 25.000 parole di testo, consentendo casi d'uso come la creazione di contenuti lunghi, conversazioni estese e ricerca e analisi di documenti.
					</p>
				</div>
			</div>
			<div class="w3-row">
				<div class="w3-col m6 w3-center w3-padding-large">
					<a href="https://ai.facebook.com/blog/large-language-model-llama-meta-ai/"><img src="https://cdn.vox-cdn.com/thumbor/qj9mp3VF6uufdDoKnCnMeBTOv-c=/0x0:2040x1360/1400x1050/filters:focal(1020x680:1021x681)/cdn.vox-cdn.com/uploads/chorus_asset/file/22977156/acastro_211101_1777_meta_0002.jpg" class="w3-round w3-image w3-hover-opacity" width="500" height="333" style="margin-top: 45%"></a>
				</div>
				<h4 style="margin-top:5%;" class="w3-center">LLaMa</h4>
				<div class="w3-col m6 w3-padding-large">
					<p>Sviluppato da Meta, LLaMA (Large Language Model Meta AI) è un modello linguistico di base all'avanguardia progettato per aiutare i ricercatori a far progredire il loro lavoro in questo sottocampo dell'IA. Modelli più piccoli e più performanti come LLaMA consentono ad altri nella comunità di ricerca che non hanno accesso a grandi quantità di infrastrutture di studiare questi modelli.
						<br><br>
						La formazione di modelli di base più piccoli come LLaMA è auspicabile nell'ampio spazio del modello linguistico perché richiede molta meno potenza di calcolo e risorse per testare nuovi approcci, convalidare il lavoro di altri ed esplorare nuovi casi d'uso. I modelli di base si addestrano su un ampio set di dati senza etichetta, il che li rende ideali per la messa a punto di una varietà di attività. META rende LLaMA disponibile in diverse dimensioni (parametri 7B, 13B, 33B e 65B).
						<br><br>
						I modelli più piccoli addestrati su più token, che sono frammenti di parole, sono più facili da riaddestrare e perfezionare per specifici potenziali casi d'uso del prodotto. META ha addestrato LLaMA 65B e LLaMA 33B su 1,4 trilioni di token. Il loro modello più piccolo, LLaMA 7B, è addestrato su un trilione di token.
					</p>
				</div>
			</div>
			<div class="w3-row">
				<div class="w3-col m6 w3-center w3-padding-large">
					<a href="https://blog.google/technology/ai/bard-google-ai-search-updates/"><img src="https://chromeunboxed.com/wp-content/uploads/2023/03/Google-Bard-Feature.png" class="w3-round w3-image w3-hover-opacity" width="500" height="333" style="margin-top: 45%"></a>
				</div>
				<h4 style="margin-top:5%;" class="w3-center">BARD</h4>
				<div class="w3-col m6 w3-padding-large">
					<p>Sviluppato da Google, BARD è un chatbot che utilizza l'apprendimento automatico e l'elaborazione del linguaggio naturale per simulare conversazioni con persone e fornire risposte alle domande. Si basa sulla tecnologia LaMDA e ha il potenziale per fornire informazioni aggiornate, a differenza di ChatGPT, che si basa su dati raccolti solo fino al 2021.
						<br><br>
						Bard cerca di combinare l'ampiezza della conoscenza del mondo con il potere, l'intelligenza e la creatività dei loro grandi modelli linguistici. Attinge alle informazioni dal web per fornire risposte fresche e di alta qualità. Bard può essere uno sbocco per la creatività e un trampolino di lancio per la curiosità, aiutando a spiegare le nuove scoperte dal telescopio spaziale James Webb della NASA a un bambino di 9 anni, o saperne di più sui migliori attaccanti del calcio in questo momento.
						<br><br>
						Lo stanno rilasciando inizialmente con la loro versione modello leggera di LaMDA. Questo modello molto più piccolo richiede una potenza di calcolo significativamente inferiore, consentendo loro di scalare a più utenti, consentendo più feedback. Combineranno il feedback esterno con i propri test interni per assicurarsi che le risposte di Bard soddisfino un livello elevato di qualità, sicurezza e fondatezza nelle informazioni del mondo reale.
					</p>
				</div>
			</div>
			<div class="w3-center">
				<img src="https://openaicom.imgix.net/b11fba8c-c51f-41c1-95b8-cc55db89af49/gpt-4-motif.svg?fm=auto&auto=compress,format&fit=min&w=1919&h=480" style="margin-top: 10%">
			</div>
		</div>
	</body>
</html>
